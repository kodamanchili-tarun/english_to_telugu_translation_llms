# English to Telugu Translation Project

## Overview
This project focuses on translation from English to Telugu using the machine translation models. We have fine-tuned the following models on the Samanantar dataset:
- MBART50
- MT5
- NLLB

We selected a subset of 60,000 parallel corpora from the available 5 million parallel corpora for our training data.

## Models
### MBART50
- Details about fine-tuning process
- Any specific configurations

### MT5
- Details about fine-tuning process
- Any specific configurations

### NLLB
- Details about fine-tuning process
- Any specific configurations

## Evaluation Metrics
Our primary evaluation metric is the BLEU score.

## Data
A data sample of 500 parallel sentences is available in the [`data`](./Data).

## Citation
@article{gala2023indictrans, 
    title={IndicTrans2: Towards High-Quality and Accessible Machine Translation Models for all 22 Scheduled Indian Languages}, 
    author={Jay Gala and Pranjal A Chitale and A K Raghavan and Varun Gumma and Sumanth Doddapaneni and Aswanth Kumar M and Janki Atul Nawale and Anupama Sujatha and Ratish Puduppully and Vivek Raghavan and Pratyush Kumar and Mitesh M Khapra and Raj Dabre and Anoop Kunchukuttan}, 
    journal={Transactions on Machine Learning Research}, 
    issn={2835-8856}, 
    year={2023}, 
    url={https://openreview.net/forum?id=vfT4YuzAYA}, 
    note={}
}

## Acknowledgements
This project is contributed to by the following collaborators:

- [Alokam Gnaneswara Sai](https://github.com/alokamgnaneswarasai)
- [Onteru Prabhas Reddy](https://github.com/prabhas2002)
- [Pallekonda Naveen Kumar](https://github.com/PNaveenKumar1)






